{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method DataFrame.info of         Island Clutch_Completion  Culmen Length (mm)  Culmen Depth (mm)  \\\n",
      "0       Biscoe               Yes                38.8               17.2   \n",
      "1    Torgersen               Yes                41.1               18.6   \n",
      "2       Biscoe               Yes                39.0               17.5   \n",
      "3        Dream                No                39.7               17.9   \n",
      "4       Biscoe               Yes                47.5               14.2   \n",
      "..         ...               ...                 ...                ...   \n",
      "269     Biscoe               Yes                44.4               17.3   \n",
      "270      Dream               Yes                36.4               17.0   \n",
      "271      Dream               Yes                42.2               18.5   \n",
      "272     Biscoe               Yes                37.8               18.3   \n",
      "273  Torgersen               Yes                42.9               17.6   \n",
      "\n",
      "     Flipper Length (mm)  Body Mass (g)     Sex  Delta 15 N (o/oo)  \\\n",
      "0                  180.0         3800.0    MALE            9.63954   \n",
      "1                  189.0         3325.0    MALE            9.32277   \n",
      "2                  186.0         3550.0  FEMALE            8.57199   \n",
      "3                  193.0         4250.0    MALE            9.25769   \n",
      "4                  209.0         4600.0  FEMALE            8.39299   \n",
      "..                   ...            ...     ...                ...   \n",
      "269                219.0         5250.0    MALE            8.13746   \n",
      "270                195.0         3325.0  FEMALE            9.17847   \n",
      "271                180.0         3550.0  FEMALE            8.04787   \n",
      "272                174.0         3400.0  FEMALE            8.73762   \n",
      "273                196.0         4700.0    MALE            8.63259   \n",
      "\n",
      "     Delta 13 C (o/oo)                              Species  \n",
      "0            -25.29856  Adelie Penguin (Pygoscelis adeliae)  \n",
      "1            -26.09989  Adelie Penguin (Pygoscelis adeliae)  \n",
      "2            -26.07188  Adelie Penguin (Pygoscelis adeliae)  \n",
      "3            -25.88798  Adelie Penguin (Pygoscelis adeliae)  \n",
      "4            -26.78733    Gentoo penguin (Pygoscelis papua)  \n",
      "..                 ...                                  ...  \n",
      "269          -26.79093    Gentoo penguin (Pygoscelis papua)  \n",
      "270          -25.23061  Adelie Penguin (Pygoscelis adeliae)  \n",
      "271          -25.49523  Adelie Penguin (Pygoscelis adeliae)  \n",
      "272          -25.09383  Adelie Penguin (Pygoscelis adeliae)  \n",
      "273          -26.23027  Adelie Penguin (Pygoscelis adeliae)  \n",
      "\n",
      "[274 rows x 10 columns]>\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(f\"./data/penguins_train.csv\")\n",
    "df = df.rename(columns={\"Clutch Completion\": \"Clutch_Completion\"})\n",
    "print(df.info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Island', 'Clutch_Completion', 'Culmen Length (mm)',\n",
       "       'Culmen Depth (mm)', 'Flipper Length (mm)', 'Body Mass (g)', 'Sex',\n",
       "       'Delta 15 N (o/oo)', 'Delta 13 C (o/oo)', 'Species'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Data Preprocessing\n",
    "def check_null_rows(df):\n",
    "    df_count_row_nan = df[df.isnull().any(axis=1)]\n",
    "    # print(f\"No.of rows with NaN values: {df_count_row_nan}\")\n",
    "    #Contains only 15 rows with NaN values\n",
    "    df = df.dropna(axis=0)\n",
    "    df.index = range(0, df.shape[0])\n",
    "    print(df.isnull().sum().sum())\n",
    "    return df \n",
    "    \n",
    "df = check_null_rows(df)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vpk/miniconda3/envs/dlenv/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/home/vpk/miniconda3/envs/dlenv/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/home/vpk/miniconda3/envs/dlenv/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def train_test_split(df, train_frac):\n",
    "    #Shuffle the dataframe\n",
    "    df = df.sample(frac=1)\n",
    "    df.index = range(0, df.shape[0])\n",
    "    train_df = df.loc[0:int(train_frac * len(df)) - 1,:]\n",
    "    test_df = df.loc[int(train_frac * len(df)):, :]\n",
    "    return train_df, test_df \n",
    "\n",
    "def encode_features(df, features):\n",
    "    label_encoder = LabelEncoder()\n",
    "    ohe = OneHotEncoder(sparse=True)\n",
    "    #NOTE: How do I get the mapping between labelEncoder and OneHotEncoder\n",
    "    #Label Encoder followed by One Hot Encoding\n",
    "    for feature in features:\n",
    "        integer_encoded = label_encoder.fit_transform(df[feature]).reshape(-1,1)\n",
    "        # print(label_encoder.classes_)\n",
    "        array_hot_encoded = ohe.fit_transform(integer_encoded).toarray()\n",
    "        # print(ohe.categories_)\n",
    "        for i_iter, categories in enumerate(label_encoder.classes_):\n",
    "            df[f\"ohe_\" + feature + \"_\" + categories] = array_hot_encoded[:, i_iter]\n",
    "    # df_check = df.loc[:, ['Island', 'ohe_Island_Biscoe', 'ohe_Island_Dream', 'ohe_Island_Torgersen']]\n",
    "    # print(df_check)\n",
    "    # df_check_1 = df.loc[:, ['Sex', 'ohe_Sex_MALE', 'ohe_Sex_FEMALE']]\n",
    "    # print(df_check_1)\n",
    "    # print(f\"Waiting for input...\")\n",
    "    return df \n",
    "\n",
    "def encode_label(df, labelname):\n",
    "    label_encoder = LabelEncoder()\n",
    "    integer_encoded = label_encoder.fit_transform(df[labelname]).reshape(-1,1)\n",
    "    df['encoded_' + labelname] = integer_encoded\n",
    "    return df \n",
    "\n",
    "\n",
    "\n",
    "train_frac = 0.7\n",
    "df_subset = df.loc[:,:]\n",
    "df_subset = encode_features(df_subset, [\"Island\", \"Sex\", \"Clutch_Completion\"])\n",
    "df_subset = encode_label(df_subset, \"Species\")\n",
    "#Train Test Split\n",
    "df_train, df_test = train_test_split(df_subset, train_frac)\n",
    "# X_train, X_test = df_train.loc[:, feature_ls], df_test.loc[:, feature_ls]\n",
    "# Y_train, Y_test = df_train.loc[:, label_ls], df_test.loc[:, label_ls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 35\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     34\u001b[0m         Y_pred_arr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate((Y_pred_arr, Y_pred), axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m---> 35\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mWaiting for input...\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[21], line 35\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     34\u001b[0m         Y_pred_arr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate((Y_pred_arr, Y_pred), axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m---> 35\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mWaiting for input...\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1457\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:701\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1152\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1135\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:312\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/dlenv/lib/python3.11/site-packages/debugpy/_vendored/pydevd/pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[1;32m   2067\u001b[0m             from_this_thread\u001b[39m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[1;32m   2069\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_threads_suspended_single_notification\u001b[39m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[0;32m-> 2070\u001b[0m         keep_suspended \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_wait_suspend(thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\n\u001b[1;32m   2072\u001b[0m frames_list \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   2074\u001b[0m \u001b[39mif\u001b[39;00m keep_suspended:\n\u001b[1;32m   2075\u001b[0m     \u001b[39m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dlenv/lib/python3.11/site-packages/debugpy/_vendored/pydevd/pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[1;32m   2103\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_input_hook()\n\u001b[1;32m   2105\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess_internal_commands()\n\u001b[0;32m-> 2106\u001b[0m     time\u001b[39m.\u001b[39msleep(\u001b[39m0.01\u001b[39m)\n\u001b[1;32m   2108\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[39mstr\u001b[39m(\u001b[39mid\u001b[39m(frame)))\n\u001b[1;32m   2110\u001b[0m \u001b[39m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def create_bootstrap_train(df):\n",
    "    t_k = df.sample(n = df.shape[0], replace=True)\n",
    "    return t_k\n",
    "\n",
    "def create_dt(X_train, Y_train):\n",
    "    clf = DecisionTreeClassifier(criterion=\"gini\", max_features=\"log2\", random_state=0)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    return clf \n",
    "\n",
    "#Creating the decision tree\n",
    "# #Testing the accuracy on the test set\n",
    "# yhat = clf.predict(X_test)\n",
    "# print(f\"Waiting for input...\")\n",
    "# accuracy_score(Y_test, yhat)\n",
    "n = 3\n",
    "feature_ls = ['ohe_Island_Biscoe', 'ohe_Island_Dream', 'ohe_Island_Torgersen', 'ohe_Sex_FEMALE', 'ohe_Sex_MALE',\\\n",
    "               'ohe_Clutch_Completion_No', 'ohe_Clutch_Completion_Yes', 'Culmen Length (mm)', 'Culmen Depth (mm)',\\\n",
    "                'Flipper Length (mm)', 'Body Mass (g)', 'Delta 15 N (o/oo)', 'Delta 13 C (o/oo)']\n",
    "label_ls = ['encoded_Species']\n",
    "clf_ls = []\n",
    "for i_iter in range(0, n):\n",
    "    df_bootstrap_train = create_bootstrap_train(df_train)\n",
    "    X_train, Y_train = df_bootstrap_train.loc[:, feature_ls].to_numpy(), df_bootstrap_train.loc[:, label_ls].to_numpy()\n",
    "    clf = create_dt(X_train, Y_train)\n",
    "    clf_ls.append(clf)\n",
    "\n",
    "#Prediction\n",
    "X_test, Y_test = df_test.loc[:, feature_ls].to_numpy(), df_test.loc[:, label_ls].to_numpy()\n",
    "for i_iter, classifier in enumerate(clf_ls):\n",
    "    Y_pred = classifier.predict(X_test).reshape(1,-1)\n",
    "    if i_iter == 0:\n",
    "        Y_pred_arr = Y_pred\n",
    "    else:\n",
    "        Y_pred_arr = np.concatenate((Y_pred_arr, Y_pred), axis=0)\n",
    "print(f\"Waiting for input...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
